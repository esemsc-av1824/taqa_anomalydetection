{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f6ba290",
   "metadata": {},
   "source": [
    "# Choke Position Model Verification\n",
    "Notebook to load a Parquet evaluation dataset, run ONNX model predictions, compute residual metrics / anomaly flags, visualize, and export an evaluation report.\n",
    "\n",
    "Model type here: XGBoost residual or Isolation Forest? We focus first on residual_downP style then choke_position IF. Adjust target/paths as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73517cd2",
   "metadata": {},
   "source": [
    "## 1. Load Dependencies and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131be8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /home/ashwinvel2000/miniconda3/envs/taqa_dl/lib/python3.11/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/ashwinvel2000/miniconda3/envs/taqa_dl/lib/python3.11/site-packages (from onnxruntime) (25.0)\n",
      "Requirement already satisfied: protobuf in /home/ashwinvel2000/miniconda3/envs/taqa_dl/lib/python3.11/site-packages (from onnxruntime) (6.31.1)\n",
      "Requirement already satisfied: sympy in /home/ashwinvel2000/miniconda3/envs/taqa_dl/lib/python3.11/site-packages (from onnxruntime) (1.13.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ashwinvel2000/miniconda3/envs/taqa_dl/lib/python3.11/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Installing collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [onnxruntime]\u001b[0m [onnxruntime]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 onnxruntime-1.22.1\n",
      "Configured model path: models_3/choke_position.onnx\n"
     ]
    }
   ],
   "source": [
    "# Install runtime deps if missing (idempotent)\n",
    "import importlib, sys, subprocess\n",
    "for pkg in ['onnxruntime','seaborn','scipy']:\n",
    "    if importlib.util.find_spec(pkg) is None:\n",
    "        subprocess.check_call([sys.executable,'-m','pip','install', pkg])\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, json, math, time\n",
    "import onnxruntime as ort\n",
    "import seaborn as sns, matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# --- Configurable paths ---\n",
    "parquet_path   = Path('training_data/synth_choke_position.parquet')  # change to real eval parquet as needed\n",
    "models_dir     = Path('models_3')                                    # directory containing ONNX models\n",
    "model_filename = 'choke_position.onnx'                               # model under test (IsolationForest)\n",
    "mad_json_path  = models_dir/'residual_mad.json'                      # only used for residual models\n",
    "target_column  = 'Choke-Position'                                    # true value column (for residual models)\n",
    "timestamp_col  = None                                                # set to column name if time axis present\n",
    "results_dir    = Path('summary') / 'model_eval'\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "print('Configured model path:', models_dir / model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890ca4b",
   "metadata": {},
   "source": [
    "## 2. Load Parquet Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1a15dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Choke-Position</th>\n",
       "      <th>ToolStateNum</th>\n",
       "      <th>Downstream-Temperature</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.395605</td>\n",
       "      <td>2</td>\n",
       "      <td>16.925677</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.736803</td>\n",
       "      <td>1</td>\n",
       "      <td>13.846731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76.113970</td>\n",
       "      <td>5</td>\n",
       "      <td>15.774798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.038594</td>\n",
       "      <td>2</td>\n",
       "      <td>16.966688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.386512</td>\n",
       "      <td>6</td>\n",
       "      <td>16.501264</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.723872</td>\n",
       "      <td>2</td>\n",
       "      <td>14.361676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1.800000</td>\n",
       "      <td>2</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>102.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>7680</td>\n",
       "      <td>16.200000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Choke-Position  ToolStateNum  Downstream-Temperature  is_anomaly\n",
       "0       77.395605             2               16.925677           0\n",
       "1       69.736803             1               13.846731           0\n",
       "2       76.113970             5               15.774798           0\n",
       "3       45.038594             2               16.966688           0\n",
       "4       64.386512             6               16.501264           0\n",
       "5       22.723872             2               14.361676           0\n",
       "6       -1.800000             2               15.500000           1\n",
       "7      102.500000             2               16.000000           1\n",
       "8       50.000000          7680               16.200000           1\n",
       "9       60.000000             2              105.000000           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_eval = pd.read_parquet(parquet_path)\n",
    "print('Shape:', df_eval.shape)\n",
    "display(df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6b6c9e",
   "metadata": {},
   "source": [
    "## 3. Quick Data Integrity & Summary Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d58c6b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtypes:\n",
      "Choke-Position            float64\n",
      "ToolStateNum                int64\n",
      "Downstream-Temperature    float64\n",
      "is_anomaly                  int64\n",
      "dtype: object\n",
      "Null counts:\n",
      "Choke-Position            0\n",
      "ToolStateNum              0\n",
      "Downstream-Temperature    0\n",
      "is_anomaly                0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Choke-Position</th>\n",
       "      <th>ToolStateNum</th>\n",
       "      <th>Downstream-Temperature</th>\n",
       "      <th>is_anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.609536</td>\n",
       "      <td>770.400000</td>\n",
       "      <td>24.707683</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.627699</td>\n",
       "      <td>2427.786472</td>\n",
       "      <td>28.230139</td>\n",
       "      <td>0.516398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.846731</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>46.278945</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.568700</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.193256</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74.519678</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>16.819574</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>102.500000</td>\n",
       "      <td>7680.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Choke-Position  ToolStateNum  Downstream-Temperature  is_anomaly\n",
       "count       10.000000     10.000000               10.000000   10.000000\n",
       "mean        56.609536    770.400000               24.707683    0.400000\n",
       "std         29.627699   2427.786472               28.230139    0.516398\n",
       "min         -1.800000      1.000000               13.846731    0.000000\n",
       "25%         46.278945      2.000000               15.568700    0.000000\n",
       "50%         62.193256      2.000000               16.100000    0.000000\n",
       "75%         74.519678      4.250000               16.819574    1.000000\n",
       "max        102.500000   7680.000000              105.000000    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target column present.\n"
     ]
    }
   ],
   "source": [
    "print('dtypes:')\n",
    "print(df_eval.dtypes)\n",
    "print('Null counts:')\n",
    "print(df_eval.isna().sum())\n",
    "display(df_eval.describe(include='all'))\n",
    "if target_column in df_eval:\n",
    "    print('Target column present.')\n",
    "else:\n",
    "    print('Warning: target column not present; residual metrics limited.')\n",
    "# Ensure no all-null feature columns\n",
    "all_null_cols = [c for c in df_eval.columns if df_eval[c].isna().all()]\n",
    "assert not all_null_cols, f'All-null columns detected: {all_null_cols}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a21c5c",
   "metadata": {},
   "source": [
    "## 4. Load ONNX Model & Extract Feature Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1442c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature order from model: ['Choke-Position', 'ToolStateNum', 'Downstream-Temperature']\n",
      "Input shape expectation (N, 3 )\n"
     ]
    }
   ],
   "source": [
    "sess = ort.InferenceSession((models_dir/model_filename).as_posix(), providers=['CPUExecutionProvider'])\n",
    "meta = sess.get_modelmeta().custom_metadata_map\n",
    "feat_order = meta.get('feature_names','').split(',') if 'feature_names' in meta else [i.name for i in sess.get_inputs()]\n",
    "feat_order = [f for f in feat_order if f]  # strip empties\n",
    "print('Feature order from model:', feat_order)\n",
    "print('Input shape expectation (N,', len(feat_order),')')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207a931c",
   "metadata": {},
   "source": [
    "## 5. Define Log Scaling & Feature Engineering Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "264bbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FEATURES = ['Upstream-Pressure','Downstream-Pressure','Downstream-Upstream-Difference']\n",
    "def make_X_eval(df, cols, target=None):\n",
    "    X = df[cols].copy()\n",
    "    for c in LOG_FEATURES:\n",
    "        if c in X.columns and c != target:\n",
    "            X[c] = np.log1p(X[c].clip(lower=0))\n",
    "    return X.astype('float32').values\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    resid = y_true - y_pred\n",
    "    abs_resid = np.abs(resid)\n",
    "    mae = float(abs_resid.mean())\n",
    "    mse = float((resid**2).mean())\n",
    "    rmse = math.sqrt(mse)\n",
    "    # R2 manual\n",
    "    ss_res = float((resid**2).sum())\n",
    "    ss_tot = float(((y_true - y_true.mean())**2).sum())\n",
    "    r2 = 1 - ss_res/ss_tot if ss_tot else float('nan')\n",
    "    return {'MAE':mae,'RMSE':rmse,'R2':r2,'MaxAbsResid': float(abs_resid.max())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77feb5c1",
   "metadata": {},
   "source": [
    "## 6. Build Feature Matrix Matching Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cb5d7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_eval shape: (10, 3)\n"
     ]
    }
   ],
   "source": [
    "X_eval = make_X_eval(df_eval, feat_order, target=None)  # IsolationForest input (no target exclusion)\n",
    "print('X_eval shape:', X_eval.shape)\n",
    "# For IF, y_true is not used; for residual model you would set y_true below.\n",
    "y_true = df_eval[target_column].astype('float32').values if target_column in df_eval else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd28b8",
   "metadata": {},
   "source": [
    "## 7. Run Batch Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaaa07f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels sample: [ 1  1  1  1  1  1  1  1 -1 -1]\n",
      "Scores sample: [ 0.1381  0.0719  0.0558  0.1115  0.0829  0.0952  0.1035  0.2956 -0.0304\n",
      " -0.0187]\n"
     ]
    }
   ],
   "source": [
    "outputs = sess.run(None, {'input': X_eval})\n",
    "# IsolationForest ONNX typically returns labels then scores\n",
    "if len(outputs)==2:\n",
    "    labels, scores = outputs\n",
    "    labels = labels.squeeze()\n",
    "    scores = scores.squeeze()\n",
    "    print('Labels sample:', labels[:10])\n",
    "    print('Scores sample:', np.round(scores[:10],4))\n",
    "else:\n",
    "    preds = outputs[0].squeeze()\n",
    "    print('Pred sample:', preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51df617c",
   "metadata": {},
   "source": [
    "## 8. Compute Residuals & Core Metrics (MAE / RMSE / R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dce03373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping residual metrics because model is IsolationForest (unsupervised).\n"
     ]
    }
   ],
   "source": [
    "is_residual = False  # set True if evaluating residual regression model instead of IF\n",
    "if is_residual and y_true is not None:\n",
    "    y_pred = outputs[0].squeeze().astype('float32')\n",
    "    metrics = compute_metrics(y_true, y_pred)\n",
    "    display(metrics)\n",
    "else:\n",
    "    print('Skipping residual metrics because model is IsolationForest (unsupervised).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74149816",
   "metadata": {},
   "source": [
    "## 9. Residual Percentiles & MAD Based Cutoff Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba514eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No residual percentile analysis (IF model or missing MAD JSON).\n"
     ]
    }
   ],
   "source": [
    "cutoff = None\n",
    "mad_limits = None\n",
    "if mad_json_path.exists():\n",
    "    try:\n",
    "        mad_limits = json.loads(mad_json_path.read_text())\n",
    "    except Exception as e:\n",
    "        print('Failed to load MAD JSON:', e)\n",
    "if is_residual and mad_limits and target_column in mad_limits:\n",
    "    cutoff = mad_limits[target_column]['cutoff']\n",
    "    resid = (y_true - y_pred)\n",
    "    abs_resid = np.abs(resid)\n",
    "    pct = np.percentile(abs_resid,[50,90,95,97.5,99])\n",
    "    print('Cutoff:', cutoff)\n",
    "    print('Percentiles 50/90/95/97.5/99:', pct)\n",
    "else:\n",
    "    print('No residual percentile analysis (IF model or missing MAD JSON).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eab951",
   "metadata": {},
   "source": [
    "## 10. Flag Anomalies & Aggregate Alert Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2005f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly rate: 20.00% (2/10)\n",
      "TP=2 FP=0 FN=2 Precision=1.00 Recall=0.50\n"
     ]
    }
   ],
   "source": [
    "if len(outputs)==2:  # IsolationForest path\n",
    "    anomaly_mask = (labels == -1)\n",
    "    rate = anomaly_mask.mean()*100\n",
    "    print(f'Anomaly rate: {rate:.2f}% ({anomaly_mask.sum()}/{len(anomaly_mask)})')\n",
    "    if 'is_anomaly' in df_eval:\n",
    "        tp = (anomaly_mask & (df_eval['is_anomaly']==1)).sum()\n",
    "        fp = (anomaly_mask & (df_eval['is_anomaly']==0)).sum()\n",
    "        fn = ((~anomaly_mask) & (df_eval['is_anomaly']==1)).sum()\n",
    "        prec = tp/(tp+fp) if (tp+fp)>0 else float('nan')\n",
    "        rec  = tp/(tp+fn) if (tp+fn)>0 else float('nan')\n",
    "        print(f'TP={tp} FP={fp} FN={fn} Precision={prec:.2f} Recall={rec:.2f}')\n",
    "else:\n",
    "    print('Not an IF output; define anomaly rule for regression if needed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9aa4b9",
   "metadata": {},
   "source": [
    "## 11. Actual vs Predicted Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e615641d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scatter skipped (IF model).\n"
     ]
    }
   ],
   "source": [
    "if is_residual and y_true is not None:\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.scatter(y_true, y_pred, s=12, alpha=0.6)\n",
    "    lims=[min(y_true.min(), y_pred.min()), max(y_true.max(), y_pred.max())]\n",
    "    plt.plot(lims, lims, 'r--', label='y=x')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs Predicted')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Scatter skipped (IF model).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a0cac",
   "metadata": {},
   "source": [
    "## 12. Residual Histogram & QQ Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0834135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual plots skipped (IF model).\n"
     ]
    }
   ],
   "source": [
    "if is_residual and y_true is not None:\n",
    "    resid = y_true - y_pred\n",
    "    fig, axes = plt.subplots(1,3, figsize=(14,4))\n",
    "    sns.histplot(resid, kde=True, ax=axes[0]); axes[0].set_title('Residuals')\n",
    "    sns.histplot(np.abs(resid), kde=True, ax=axes[1]); axes[1].set_title('|Residuals|')\n",
    "    stats.probplot(resid, dist='norm', plot=axes[2])\n",
    "    axes[2].set_title('QQ Plot')\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print('Residual plots skipped (IF model).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038cf36e",
   "metadata": {},
   "source": [
    "## 13. Time Series Plot With Anomaly Overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16a0d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time series plot skipped (missing timestamp or not IF).\n"
     ]
    }
   ],
   "source": [
    "if timestamp_col and timestamp_col in df_eval and len(outputs)==2:\n",
    "    df_ts = df_eval.copy().sort_values(timestamp_col)\n",
    "    df_ts['anomaly'] = (labels==-1)\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.plot(df_ts[timestamp_col], df_ts[target_column] if target_column in df_ts else df_ts[feat_order[0]], label='Signal')\n",
    "    plt.scatter(df_ts.loc[df_ts.anomaly, timestamp_col],\n",
    "                (df_ts.loc[df_ts.anomaly, target_column] if target_column in df_ts else df_ts.loc[df_ts.anomaly, feat_order[0]]),\n",
    "                color='red', s=30, label='Anomaly')\n",
    "    plt.legend(); plt.title('Time Series with Anomalies'); plt.show()\n",
    "else:\n",
    "    print('Time series plot skipped (missing timestamp or not IF).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fae789",
   "metadata": {},
   "source": [
    "## 14. Per-Window Stability / Drift Checks (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a69a383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift check skipped (need timestamp + residual model).\n"
     ]
    }
   ],
   "source": [
    "if timestamp_col and timestamp_col in df_eval and is_residual and y_true is not None:\n",
    "    df_eval['_resid'] = y_true - y_pred\n",
    "    win = '1H'  # adjust resample window\n",
    "    drift = df_eval.set_index(timestamp_col)['_resid'].resample(win).agg(['mean','std'])\n",
    "    display(drift.head())\n",
    "    drift.plot(subplots=True, figsize=(10,4), title='Residual Drift'); plt.tight_layout()\n",
    "else:\n",
    "    print('Drift check skipped (need timestamp + residual model).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0790eeb8",
   "metadata": {},
   "source": [
    "## 15. Evaluate Multiple Models in Directory (Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd634000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed for delta_temp_open.onnx \"None of [Index(['DeltaTemperature'], dtype='object')] are in the [columns]\"\n",
      "Failed for full_vectors_if.onnx \"['Battery-Voltage', 'Upstream-Pressure', 'Downstream-Pressure', 'Downstream-Upstream-Difference', 'Upstream-Temperature'] not in index\"\n",
      "Failed for pressure_pair_open.onnx \"None of [Index(['Upstream-Pressure', 'Downstream-Pressure'], dtype='object')] are in the [columns]\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>anomaly_rate_pct</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>choke_position.onnx</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  file  anomaly_rate_pct   n\n",
       "0  choke_position.onnx              20.0  10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_if_model(fp, df):\n",
    "    s = ort.InferenceSession(fp.as_posix(), providers=['CPUExecutionProvider'])\n",
    "    feats = s.get_modelmeta().custom_metadata_map.get('feature_names','').split(',')\n",
    "    feats = [f for f in feats if f] or [i.name for i in s.get_inputs()]\n",
    "    X = make_X_eval(df, feats)\n",
    "    lbl, *_ = s.run(None, {'input': X})\n",
    "    lbl = lbl.squeeze()\n",
    "    rate = (lbl==-1).mean()*100\n",
    "    return {'file': fp.name, 'anomaly_rate_pct': rate, 'n': len(lbl)}\n",
    "\n",
    "multi_summary = []\n",
    "for fp in sorted(models_dir.glob('*.onnx')):\n",
    "    if 'residual' in fp.name:  # skip residual for simplicity here\n",
    "        continue\n",
    "    try:\n",
    "        multi_summary.append(evaluate_if_model(fp, df_eval))\n",
    "    except Exception as e:\n",
    "        print('Failed for', fp.name, e)\n",
    "multi_df = pd.DataFrame(multi_summary)\n",
    "display(multi_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e628e3c",
   "metadata": {},
   "source": [
    "## 16. Export Evaluation Report & Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = {}\n",
    "if len(outputs)==2:\n",
    "    report['anomaly_rate_pct'] = float((labels==-1).mean()*100)\n",
    "    if 'is_anomaly' in df_eval:\n",
    "        anomaly_mask = labels==-1\n",
    "        report['tp'] = int((anomaly_mask & (df_eval['is_anomaly']==1)).sum())\n",
    "        report['fp'] = int((anomaly_mask & (df_eval['is_anomaly']==0)).sum())\n",
    "        report['fn'] = int(((~anomaly_mask) & (df_eval['is_anomaly']==1)).sum())\n",
    "        report['precision'] = report['tp']/ (report['tp']+report['fp']) if (report['tp']+report['fp'])>0 else None\n",
    "        report['recall'] = report['tp']/ (report['tp']+report['fn']) if (report['tp']+report['fn'])>0 else None\n",
    "else:\n",
    "    if is_residual and y_true is not None:\n",
    "        report.update(metrics)\n",
    "(results_dir/'choke_position_eval.json').write_text(json.dumps(report, indent=2))\n",
    "print('Saved report to', results_dir/'choke_position_eval.json')\n",
    "# Save per-row if anomalies present\n",
    "if len(outputs)==2:\n",
    "    out_df = df_eval.copy()\n",
    "    out_df['if_label'] = labels\n",
    "    out_df.to_parquet(results_dir/'choke_position_eval_rows.parquet', index=False)\n",
    "    print('Saved per-row parquet.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd746f",
   "metadata": {},
   "source": [
    "## 17. Reusable Utility Functions Cell\n",
    "(Copied earlier; consolidate if refactoring into module.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taqa_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
